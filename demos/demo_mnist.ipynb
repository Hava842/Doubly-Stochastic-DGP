{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification\n",
    "\n",
    "Timings here are for a machine with a K80 GPU (an Azure NC6 instance). Running with a CPU only machine is going to quite a bit slower. \n",
    "\n",
    "**This requires tensorflow 1.0. For some reason things are breaking on tensorflow 1.1 (https://github.com/GPflow/GPflow/issues/415)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7', '/usr/lib/python2.7/dist-packages/ubuntu-sso-client', '/usr/lib/python2.7/dist-packages/wx-2.8-gtk2-unicode', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/homes/mlghomes/mh740/.ipython', '/homes/mlghomes/mh740/GPflow', '/homes/mlghomes/mh740/Doubly-Stochastic-DGP/doubly_stochastic_dgp']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/homes/mlghomes/mh740/GPflow')\n",
    "sys.path.append('/homes/mlghomes/mh740/Doubly-Stochastic-DGP/doubly_stochastic_dgp')\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpflow.likelihoods import MultiClass\n",
    "from gpflow.kernels import RBF, White, Linear, Matern32, Matern52\n",
    "from gpflow.svgp import SVGP\n",
    "from gpflow.gpr import GPR\n",
    "\n",
    "from gpflow.param import AutoFlow\n",
    "\n",
    "from scipy.stats import mode\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "from get_data import get_mnist_data\n",
    "from dgp import DGP\n",
    "\n",
    "import time\n",
    "\n",
    "X, Y, Xs, Ys = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 100 inducing points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 30\n",
    "Z = kmeans2(X, M, minit='points')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly annoyingly,  `AutoFlow` takes `Ynew` as a `float_type` in `predict_density`, but for the mutliclass likelihood the input is `tf.int32` (also the number of dimensions are different). We defined both versions in our `DGP` class, but as a workaround for `SVGP` we just override the behaviour:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiClassSVPG(SVGP):\n",
    "    @AutoFlow((tf.float64, [None, None]), (tf.int32, [None,]))\n",
    "    def predict_density(self, Xnew, Ynew):\n",
    "        pred_f_mean, pred_f_var = self.build_predict(Xnew)\n",
    "        return self.likelihood.predict_density(pred_f_mean, pred_f_var, Ynew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare three models: an ordinary sparse GP and DGPs with 2 and 3 layers. \n",
    "\n",
    "We'll use a batch size of 1000 for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_sgp = MultiClassSVPG(X, Y.reshape(-1, 1).astype(np.float64), RBF(784, lengthscales=2, variance=2), \n",
    "            MultiClass(10), Z, \n",
    "            num_latent=10, minibatch_size=10000, whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dgp(L):\n",
    "    kernels = [RBF(784, lengthscales=2., variance=2.)]\n",
    "    for l in range(L-1):\n",
    "        kernels.append(RBF(30, lengthscales=2., variance=2.))\n",
    "    model = DGP(X, Y, Z, kernels, MultiClass(10), \n",
    "                num_samples=1,\n",
    "                minibatch_size=10000,\n",
    "                num_latent_Y=10)\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.q_sqrt = layer.q_sqrt.value * 1e-5 \n",
    "    \n",
    "    return model\n",
    "m_dgp2 = make_dgp(2)\n",
    "m_dgp3 = make_dgp(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SGP model we'll calcuate accuracy by simply taking the max mean prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assess_model_sgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch)\n",
    "    l = model.predict_density(X_batch, Y_batch)\n",
    "    a = (np.argmax(m, 1)==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DGP models we have stochastic predictions. We need a single prediction for each datum, so to do this we take $S$ samples for the one-hot predictions ($(S, N, 10)$ matrices for mean and var), then we take the max over the class means (to give a $(S, N)$ matrix), and finally we take the modal class over the samples (to give a vector of length $N$):\n",
    "\n",
    "We'll use 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = 100\n",
    "def assess_model_dgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch, S)\n",
    "    l = model.predict_density(X_batch, Y_batch, S)\n",
    "    a = (mode(np.argmax(m, 2), 0)[0].flatten()==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need batch predictions (we might run out of memory otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_assess(model, assess_model, X, Y):\n",
    "    n_batches = int(len(X)/1000)\n",
    "    lik, acc = [], []\n",
    "    for X_batch, Y_batch in zip(np.split(X, n_batches), np.split(Y, n_batches)):\n",
    "        l, a = assess_model(model, X_batch, Y_batch)\n",
    "        lik.append(l)\n",
    "        acc.append(a)\n",
    "    lik = np.concatenate(lik, 0)\n",
    "    acc = np.array(np.concatenate(acc, 0), dtype=float)\n",
    "    return np.average(lik), np.average(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll use the following callback to log what's going on. We'll train for 10000 iterations, printing every 1000 to see how convergence is doing. We'll predict also at the training data to see what's going (we don't use a validation set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CB(object):\n",
    "    def __init__(self, model, assess_model):\n",
    "        self.model = model\n",
    "        self.assess_model = assess_model\n",
    "        self.i = 0\n",
    "        self.t = time.time()\n",
    "        self.train_time = 0\n",
    "        self.ob = []\n",
    "        self.train_lik = []\n",
    "        self.train_acc = []\n",
    "    def cb(self, x):\n",
    "        self.i += 1\n",
    "        if self.i % 100 == 0:\n",
    "            # time how long we've be training \n",
    "            self.train_time += time.time() - self.t\n",
    "            self.t = time.time()\n",
    "            \n",
    "            # assess the model on the training data\n",
    "            self.model.set_state(x)\n",
    "            lik, acc = batch_assess(self.model, self.assess_model, X, Y)\n",
    "            self.train_lik.append(lik)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            # calculate the objective, averaged over S samples \n",
    "            ob = 0\n",
    "            for _ in range(1):\n",
    "                ob += self.model.compute_log_likelihood()/float(1)\n",
    "            self.ob.append(ob)\n",
    "            \n",
    "            st = 'it: {}, ob: {:.1f}, train lik: {:.4f}, train acc {:.4f}'\n",
    "            print st.format(self.i, ob, lik, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to go\n",
    "\n",
    "The sparse GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_sgp = CB(m_sgp, assess_model_sgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 100, ob: -364953.7, train lik: -1.2899, train acc 0.7831\n",
      "it: 200, ob: -226536.2, train lik: -0.6776, train acc 0.8724\n",
      "it: 300, ob: -130017.8, train lik: -0.4011, train acc 0.8982\n",
      "it: 400, ob: -78092.8, train lik: -0.2813, train acc 0.9201\n",
      "it: 500, ob: -67103.4, train lik: -0.2514, train acc 0.9301\n",
      "it: 600, ob: -59758.3, train lik: -0.2338, train acc 0.9360\n",
      "it: 700, ob: -54670.9, train lik: -0.2257, train acc 0.9390\n",
      "it: 800, ob: -53411.8, train lik: -0.2188, train acc 0.9418\n",
      "it: 900, ob: -51405.3, train lik: -0.2129, train acc 0.9442\n",
      "it: 1000, ob: -48470.8, train lik: -0.2088, train acc 0.9459\n",
      "it: 1100, ob: -48456.3, train lik: -0.2031, train acc 0.9473\n",
      "it: 1200, ob: -46191.2, train lik: -0.2030, train acc 0.9484\n",
      "it: 1300, ob: -45351.6, train lik: -0.1992, train acc 0.9504\n",
      "it: 1400, ob: -43376.3, train lik: -0.1960, train acc 0.9510\n",
      "it: 1500, ob: -43182.0, train lik: -0.1957, train acc 0.9516\n",
      "it: 1600, ob: -42432.6, train lik: -0.1918, train acc 0.9526\n",
      "it: 1700, ob: -43986.7, train lik: -0.1924, train acc 0.9526\n",
      "it: 1800, ob: -44296.9, train lik: -0.1875, train acc 0.9545\n",
      "it: 1900, ob: -42035.9, train lik: -0.1863, train acc 0.9547\n",
      "it: 2000, ob: -41848.0, train lik: -0.1866, train acc 0.9553\n",
      "it: 2100, ob: -41502.6, train lik: -0.1826, train acc 0.9559\n",
      "it: 2200, ob: -41628.9, train lik: -0.1855, train acc 0.9560\n",
      "it: 2300, ob: -40590.1, train lik: -0.1831, train acc 0.9560\n",
      "it: 2400, ob: -43823.6, train lik: -0.1800, train acc 0.9574\n",
      "it: 2500, ob: -41330.1, train lik: -0.1786, train acc 0.9573\n",
      "it: 2600, ob: -39872.0, train lik: -0.1774, train acc 0.9580\n",
      "it: 2700, ob: -40543.1, train lik: -0.1787, train acc 0.9585\n",
      "it: 2800, ob: -38474.3, train lik: -0.1787, train acc 0.9584\n",
      "it: 2900, ob: -38833.5, train lik: -0.1774, train acc 0.9585\n",
      "it: 3000, ob: -41196.8, train lik: -0.1761, train acc 0.9593\n",
      "it: 3100, ob: -41984.9, train lik: -0.1735, train acc 0.9599\n",
      "it: 3200, ob: -39291.0, train lik: -0.1742, train acc 0.9593\n",
      "it: 3300, ob: -39758.7, train lik: -0.1698, train acc 0.9609\n",
      "it: 3400, ob: -41224.8, train lik: -0.1728, train acc 0.9601\n",
      "it: 3500, ob: -38881.0, train lik: -0.1705, train acc 0.9609\n",
      "it: 3600, ob: -37473.4, train lik: -0.1710, train acc 0.9606\n",
      "it: 3700, ob: -39848.4, train lik: -0.1715, train acc 0.9608\n",
      "it: 3800, ob: -39000.8, train lik: -0.1694, train acc 0.9614\n",
      "it: 3900, ob: -38036.0, train lik: -0.1682, train acc 0.9613\n",
      "it: 4000, ob: -39500.4, train lik: -0.1706, train acc 0.9611\n",
      "it: 4100, ob: -37643.9, train lik: -0.1665, train acc 0.9618\n",
      "it: 4200, ob: -39610.2, train lik: -0.1666, train acc 0.9619\n",
      "it: 4300, ob: -39345.3, train lik: -0.1681, train acc 0.9617\n",
      "it: 4400, ob: -37224.0, train lik: -0.1674, train acc 0.9618\n",
      "it: 4500, ob: -37438.3, train lik: -0.1655, train acc 0.9624\n",
      "it: 4600, ob: -39115.5, train lik: -0.1650, train acc 0.9627\n",
      "it: 4700, ob: -39607.7, train lik: -0.1671, train acc 0.9623\n",
      "it: 4800, ob: -38312.1, train lik: -0.1643, train acc 0.9626\n",
      "it: 4900, ob: -40158.4, train lik: -0.1630, train acc 0.9626\n",
      "it: 5000, ob: -38069.7, train lik: -0.1638, train acc 0.9627\n",
      "it: 5100, ob: -39915.9, train lik: -0.1637, train acc 0.9628\n",
      "it: 5200, ob: -38366.7, train lik: -0.1624, train acc 0.9631\n",
      "it: 5300, ob: -38821.2, train lik: -0.1613, train acc 0.9636\n",
      "it: 5400, ob: -38597.9, train lik: -0.1610, train acc 0.9632\n",
      "it: 5500, ob: -37126.7, train lik: -0.1602, train acc 0.9637\n",
      "it: 5600, ob: -38952.7, train lik: -0.1607, train acc 0.9633\n",
      "it: 5700, ob: -39813.2, train lik: -0.1613, train acc 0.9634\n",
      "it: 5800, ob: -38303.8, train lik: -0.1611, train acc 0.9634\n",
      "it: 5900, ob: -38435.3, train lik: -0.1604, train acc 0.9633\n",
      "it: 6000, ob: -39937.2, train lik: -0.1588, train acc 0.9640\n",
      "it: 6100, ob: -39351.2, train lik: -0.1610, train acc 0.9634\n",
      "it: 6200, ob: -39553.6, train lik: -0.1591, train acc 0.9642\n",
      "it: 6300, ob: -37383.4, train lik: -0.1604, train acc 0.9638\n",
      "it: 6400, ob: -37936.7, train lik: -0.1589, train acc 0.9639\n",
      "it: 6500, ob: -38343.1, train lik: -0.1589, train acc 0.9643\n",
      "it: 6600, ob: -37635.7, train lik: -0.1587, train acc 0.9643\n",
      "it: 6700, ob: -37144.5, train lik: -0.1591, train acc 0.9641\n",
      "it: 6800, ob: -37989.0, train lik: -0.1582, train acc 0.9643\n",
      "it: 6900, ob: -39581.9, train lik: -0.1568, train acc 0.9645\n",
      "it: 7000, ob: -37973.3, train lik: -0.1576, train acc 0.9645\n",
      "it: 7100, ob: -38056.9, train lik: -0.1575, train acc 0.9645\n",
      "it: 7200, ob: -37919.6, train lik: -0.1566, train acc 0.9645\n",
      "it: 7300, ob: -38279.4, train lik: -0.1572, train acc 0.9646\n",
      "it: 7400, ob: -37067.4, train lik: -0.1570, train acc 0.9647\n",
      "it: 7500, ob: -36624.9, train lik: -0.1559, train acc 0.9646\n",
      "it: 7600, ob: -39433.4, train lik: -0.1552, train acc 0.9648\n",
      "it: 7700, ob: -38136.0, train lik: -0.1563, train acc 0.9647\n",
      "it: 7800, ob: -37011.2, train lik: -0.1560, train acc 0.9649\n",
      "it: 7900, ob: -38275.4, train lik: -0.1574, train acc 0.9643\n",
      "it: 8000, ob: -39733.9, train lik: -0.1548, train acc 0.9650\n",
      "it: 8100, ob: -38671.2, train lik: -0.1561, train acc 0.9646\n",
      "it: 8200, ob: -37886.0, train lik: -0.1572, train acc 0.9645\n",
      "it: 8300, ob: -36908.2, train lik: -0.1554, train acc 0.9653\n",
      "it: 8400, ob: -38721.4, train lik: -0.1563, train acc 0.9640\n",
      "it: 8500, ob: -37978.1, train lik: -0.1569, train acc 0.9647\n",
      "it: 8600, ob: -36944.3, train lik: -0.1541, train acc 0.9652\n",
      "it: 8700, ob: -39094.3, train lik: -0.1538, train acc 0.9653\n",
      "it: 8800, ob: -37522.4, train lik: -0.1529, train acc 0.9653\n",
      "it: 8900, ob: -38276.7, train lik: -0.1549, train acc 0.9650\n",
      "it: 9000, ob: -38898.9, train lik: -0.1530, train acc 0.9654\n",
      "it: 9100, ob: -37439.9, train lik: -0.1533, train acc 0.9657\n",
      "it: 9200, ob: -37633.0, train lik: -0.1540, train acc 0.9653\n",
      "it: 9300, ob: -37046.8, train lik: -0.1553, train acc 0.9653\n",
      "it: 9400, ob: -36332.4, train lik: -0.1535, train acc 0.9654\n",
      "it: 9500, ob: -38333.3, train lik: -0.1522, train acc 0.9657\n",
      "it: 9600, ob: -37971.7, train lik: -0.1531, train acc 0.9658\n",
      "it: 9700, ob: -36880.0, train lik: -0.1530, train acc 0.9653\n",
      "it: 9800, ob: -35964.6, train lik: -0.1530, train acc 0.9652\n",
      "it: 9900, ob: -37943.2, train lik: -0.1543, train acc 0.9651\n",
      "it: 10000, ob: -37152.6, train lik: -0.1531, train acc 0.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 38445.024020967016\n",
       "     jac: array([-0.        , -0.        , -0.        , ..., -0.2239916 ,\n",
       "       -0.22270208,  0.33455356])\n",
       " message: 'Finished iterations.'\n",
       "  status: 'Finished iterations.'\n",
       " success: True\n",
       "       x: array([ 0.        ,  0.        ,  0.        , ..., -0.05303204,\n",
       "       -0.04260791,  0.23412898])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sgp.optimize(tf.train.AdamOptimizer(0.01), maxiter=10000, callback=cb_sgp.cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgp total train time 1895.5112\n",
      "spg test lik: -0.1594, test acc 0.9592\n"
     ]
    }
   ],
   "source": [
    "print 'sgp total train time {:.4f}'.format(cb_sgp.train_time)\n",
    "l, a = batch_assess(m_sgp, assess_model_sgp, Xs, Ys)\n",
    "print 'spg test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more inducing points improves things, but at the expense of very slow computation (500 inducing points takes about a day)\n",
    "\n",
    "The two layer DGP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([Dimension(None), Dimension(None)]), TensorShape([Dimension(None), Dimension(None)]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1000,) for Tensor u'Placeholder_10:0', which has shape '(?, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2cf517195514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcb_dgp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_dgp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massess_model_dgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm_dgp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_dgp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'dgp2 total train time {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_dgp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_assess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_dgp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massess_model_dgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'dgp2 test lik: {:.4f}, test acc {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/mlghomes/mh740/GPflow/gpflow/model.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, method, tol, callback, maxiter, **kw)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/mlghomes/mh740/GPflow/gpflow/model.pyc\u001b[0m in \u001b[0;36m_optimize_tf\u001b[0;34m(self, method, callback, maxiter)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_fevals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                     \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9a3e3b40612a>\u001b[0m in \u001b[0;36mcb\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# assess the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_assess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massess_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_lik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlik\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0ee710a709d6>\u001b[0m in \u001b[0;36mbatch_assess\u001b[0;34m(model, assess_model, X, Y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-65dba8f27122>\u001b[0m in \u001b[0;36massess_model_dgp\u001b[0;34m(model, X_batch, Y_batch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massess_model_dgp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/mlghomes/mh740/GPflow/gpflow/param.pyc\u001b[0m in \u001b[0;36mrunnable\u001b[0;34m(instance, *np_args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'free_vars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_free_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feed_dict_keys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tf_result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1000,) for Tensor u'Placeholder_10:0', which has shape '(?, ?)'"
     ]
    }
   ],
   "source": [
    "cb_dgp2 = CB(m_dgp2, assess_model_dgp)\n",
    "m_dgp2.optimize(tf.train.AdamOptimizer(0.01), maxiter=10000, callback=cb_dgp2.cb)\n",
    "print 'dgp2 total train time {:.4f}'.format(cb_dgp2.train_time)\n",
    "l, a = batch_assess(m_dgp2, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp2 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And the three layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb_dgp3 = CB(m_dgp3, assess_model_dgp)\n",
    "m_dgp3.optimize(tf.train.AdamOptimizer(0.01), maxiter=10000, callback=cb_dgp3.cb)\n",
    "print 'dgp3 total train time {:.4f}'.format(cb_dgp3.train_time)\n",
    "l, a = batch_assess(m_dgp3, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp3 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 layer DGP is best on both accuracy and likelihood, though the improvement over the 2 layer is slight. \n",
    "\n",
    "We can see how they've done over the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(cb_sgp.train_acc, label='sgp')\n",
    "plt.plot(cb_dgp2.train_acc, label='dgp2')\n",
    "plt.plot(cb_dgp3.train_acc, label='dgp3')\n",
    "plt.title('train accuray')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cb_sgp.train_lik, label='sgp')\n",
    "plt.plot(cb_dgp2.train_lik, label='dgp2')\n",
    "plt.plot(cb_dgp3.train_lik, label='dgp3')\n",
    "plt.title('train likelihood')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
